# 
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

##enable wds.linkis.test.mode where use knife4j
#wds.linkis.test.mode=true

wds.linkis.server.version=v1

##spring conf
wds.linkis.gateway.url=http://127.0.0.1:9001
wds.linkis.eureka.defaultZone=http://127.0.0.1:20303/eureka/
##mybatis
wds.linkis.server.mybatis.datasource.url=
wds.linkis.server.mybatis.datasource.username=
wds.linkis.server.mybatis.datasource.password=
# mysql
wds.linkis.mysql.is.encrypt=false
linkis.mysql.strong.security.enable=false
linkis.mysql.force.params=allowLoadLocalInfile=false&autoDeserialize=false&allowLocalInfile=false&allowUrlInLocalInfile=false
linkis.mysql.sensitive.params=allowLoadLocalInfile,autoDeserialize,allowLocalInfile,allowUrlInLocalInfile,#

#hadoop/hive/spark config
#hadoop.config.dir=/appcom/config/hadoop-config
#hive.config.dir=
#spark.config.dir


#wds.linkis.keytab.enable=true
#wds.linkis.keytab.file=/appcom/keytab/


##file path
wds.linkis.filesystem.root.path=file:///tmp/linkis/
wds.linkis.filesystem.hdfs.root.path=hdfs:///tmp/linkis/
##bml path:default use hdfs
wds.linkis.bml.is.hdfs=true
#wds.linkis.bml.hdfs.prefix=/apps-data
#wds.linkis.bml.local.prefix=/data/dss/bml

##engine Version
#wds.linkis.spark.engine.version=
#wds.linkis.hive.engine.version=
#wds.linkis.python.engine.version=

#LinkisHome
wds.linkis.home=/appcom/Install/LinkisInstall
#Linkis governance station administrators
wds.linkis.governance.station.admin=hadoop
#wds.linkis.gateway.conf.publicservice.list=query,jobhistory,application,configuration,filesystem,udf,variable,microservice,errorcode,bml,datasource

#wds.linkis.prometheus.enable=true
wds.linkis.server.user.restful.uri.pass.auth=/actuator/prometheus,/api/rest_j/v1/offline,/api/rest_j/v1/doc.html,/api/rest_j/v1/swagger-resources,/api/rest_j/v1/webjars,/api/rest_j/v1/v2/api-docs

wds.linkis.gateway.conf.metadataquery.list=metadatamanager,metadataquery
spring.spring.servlet.multipart.max-file-size=500MB
spring.spring.servlet.multipart.max-request-size=500MB

# note:value of zero means Jetty will never write to disk. https://github.com/spring-projects/spring-boot/issues/9073
spring.spring.servlet.multipart.file-size-threshold=50MB
# note: org.springframework.cloud.config.client.ConfigServiceBootstrapConfiguration.configServicePropertySource need to disable
spring.spring.cloud.config.enabled=false

# linkis user ticket sso
# redis stand-alone
linkis.session.redis.host=127.0.0.1
linkis.session.redis.port=6379
### redis sentinel model config sentinel-master-name
#linkis.session.redis.sentinel.master=
#### 192.168.1.1:6381,192.168.2.1:6381,192.168.3.1:6381
#linkis.session.redis.sentinel.nodes=
# redis password
linkis.session.redis.password=test123
# redis sso switch
linkis.session.redis.cache.enabled=false